{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installare tutti i pacchetti necessari e scaricare il modello it_core_news_md (italiano, dimensione media) di spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15765,
     "status": "ok",
     "timestamp": 1732038555869,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "FUqYHpEabkph",
    "outputId": "983058e8-91f3-43f6-c59c-281e3e1c1f4c"
   },
   "outputs": [],
   "source": [
    "!pip install gensim spacy numpy torch networkx scikit-learn\n",
    "!python -m spacy download it_core_news_md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaricare gli embeddings di fast text, saranno utili per la creazione di vettori a partire dalle parole. I vettori saranno utili per calcolare successivamente la similarità coseno e per eseguire una clusterizzazione dei concetti nel metodo extract_concepts_clustering. Gli embedding sono scaricati in formato binario perchè richiede meno risorse per la lettura (il pacchetto è più pesante però)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391725,
     "status": "ok",
     "timestamp": 1732039041650,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "JVrdiizHeDoN",
    "outputId": "8c542b0c-af14-49ab-8651-61ab3212d771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-19 17:50:50--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.bin.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.25, 13.226.210.78, 13.226.210.15, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4502592726 (4.2G) [application/octet-stream]\n",
      "Saving to: ‘cc.it.300.bin.gz’\n",
      "\n",
      "cc.it.300.bin.gz    100%[===================>]   4.19G  45.0MB/s    in 65s     \n",
      "\n",
      "2024-11-19 17:51:55 (66.3 MB/s) - ‘cc.it.300.bin.gz’ saved [4502592726/4502592726]\n",
      "\n",
      "gzip: cc.it.300.bin already exists; do you wish to overwrite (y or n)? y\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "# Esempio di URL diretto (verifica sempre l'URL corretto sul sito ufficiale)\n",
    "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.bin.gz'\n",
    "\n",
    "# Scarica il file\n",
    "!wget -O cc.it.300.bin.gz $url\n",
    "\n",
    "# Estrai il file compresso\n",
    "!gunzip cc.it.300.bin.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaricare fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70018,
     "status": "ok",
     "timestamp": 1732039602756,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "EmR95B6wmXUN",
    "outputId": "1413247f-f3fa-4185-f1e1-e3ebfe1567f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastText\n",
      "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pybind11>=2.2 (from fastText)\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fastText) (75.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastText) (1.26.4)\n",
      "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Building wheels for collected packages: fastText\n",
      "  Building wheel for fastText (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastText: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296182 sha256=66d7d00e464792b2c6ec253d530f49f8b3c8b11afc2040c68a10edd9f2c2acd4\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
      "Successfully built fastText\n",
      "Installing collected packages: pybind11, fastText\n",
      "Successfully installed fastText-0.9.3 pybind11-2.13.6\n"
     ]
    }
   ],
   "source": [
    "!pip install fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella cella successiva c'è un semplice controllo, utilizzando il modulo OS, per verificare la presenza degli embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1732039070533,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "NOwmkqzReOMd",
    "outputId": "6d5e938d-5804-4fb4-a8e8-cc3fe99f55c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il file FastText è stato scaricato e decompresso correttamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "fasttext_path = '/content/cc.it.300.bin'\n",
    "\n",
    "if os.path.exists(fasttext_path):\n",
    "    print(\"Il file FastText è stato scaricato e decompresso correttamente.\")\n",
    "else:\n",
    "    print(\"Errore nel download o nella decompressione del file FastText.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella, oltre a importare tutti i moduli necessari per le classi successive, viene caricato il modello spacy e vengono caricati gli embedding attraverso il metodo load_model di fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62974,
     "status": "ok",
     "timestamp": 1732042778725,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "2lVDAwZwyadj",
    "outputId": "bc890479-768c-451e-f7cc-0fd205f6000d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy usa la GPU: True\n",
      "Caricamento del modello SpaCy...\n",
      "Modello 'it_core_news_md' caricato con successo.\n",
      "Caricamento degli embedding FastText...\n",
      "Embedding FastText caricati con successo.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "from fasttext import load_model\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "print(\"SpaCy usa la GPU:\", spacy.prefer_gpu())\n",
    "# -------------------------------\n",
    "# Caricamento del Modello Linguistico e degli Embedding\n",
    "# -------------------------------\n",
    "\n",
    "# Percorso al modello FastText binario\n",
    "fasttext_path = '/content/cc.it.300.bin'\n",
    "\n",
    "# Caricamento del modello di Spacy\n",
    "print(\"Caricamento del modello SpaCy...\")\n",
    "spacy_model = spacy.load(\"it_core_news_md\")\n",
    "print(\"Modello 'it_core_news_md' caricato con successo.\")\n",
    "\n",
    "# Caricamento degli embedding FastText\n",
    "print(\"Caricamento degli embedding FastText...\")\n",
    "try:\n",
    "    fasttext_model = load_model(fasttext_path)\n",
    "    print(\"Embedding FastText caricati con successo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il caricamento del modello FastText: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella, oltre a caricare altri modulo utili per la gestione del grafo, creiamo una funzione a livello globale per calcolare la similarità tra vettori, che verrà successivamente chiamata. Successivamente creiamo le classi di cui abbiamo bisogno per creare il grafo di conoscenza (ThreeDimensionalGraphModel) ed estrarre concetti dalla frase input attraverso l'uso del modello NLP (classe TextToGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWgo7CbPfBiu"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Funzione per calcolare la similarità coseno\n",
    "def calculate_similarity(word1, word2, model):\n",
    "    try:\n",
    "        vec1 = model.get_word_vector(word1)\n",
    "        vec2 = model.get_word_vector(word2)\n",
    "        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        return similarity\n",
    "    except KeyError:\n",
    "        print(f\"Una delle parole '{word1}' o '{word2}' non è nel modello FastText.\")\n",
    "        return 0.0\n",
    "\n",
    "# Classe ThreeDimensionalGraphModel\n",
    "class ThreeDimensionalGraphModel:\n",
    "    def __init__(self):\n",
    "        self.G = nx.Graph()\n",
    "        self.C = {}  # Dizionario di associazione concetti-nodi\n",
    "        self.truth_node = 'Verità'\n",
    "        self.G.add_node(self.truth_node)\n",
    "\n",
    "    def add_connection(self, node_i, node_j, weight=1, probability=1.0, relation_type='default'):\n",
    "        self.G.add_node(node_i)\n",
    "        self.G.add_node(node_j)\n",
    "        if self.G.has_edge(node_i, node_j):\n",
    "            self.G[node_i][node_j]['weight'] += weight\n",
    "            self.G[node_i][node_j]['probability'] = (\n",
    "                self.G[node_i][node_j]['probability'] + probability\n",
    "            ) / 2\n",
    "            if 'relation_types' not in self.G[node_i][node_j]:\n",
    "                self.G[node_i][node_j]['relation_types'] = set()\n",
    "            self.G[node_i][node_j]['relation_types'].add(relation_type)\n",
    "        else:\n",
    "            self.G.add_edge(node_i, node_j, weight=weight, probability=probability, relation_types={relation_type})\n",
    "\n",
    "    def add_concept_association(self, concept, node, strength=1.0):\n",
    "        if concept not in self.C:\n",
    "            self.C[concept] = {}\n",
    "        if node not in self.C[concept]:\n",
    "            self.C[concept][node] = 0\n",
    "        self.C[concept][node] += strength\n",
    "\n",
    "    def save_state(self, filename):\n",
    "        with open(filename + '_G.pkl', 'wb') as f:\n",
    "            pickle.dump(self.G, f)\n",
    "        with open(filename + '_C.pkl', 'wb') as f:\n",
    "            pickle.dump(self.C, f)\n",
    "        print(\"Stato del grafo e delle associazioni salvati.\")\n",
    "\n",
    "    def load_state(self, filename):\n",
    "        with open(filename + '_G.pkl', 'rb') as f:\n",
    "            self.G = pickle.load(f)\n",
    "        with open(filename + '_C.pkl', 'rb') as f:\n",
    "            self.C = pickle.load(f)\n",
    "        print(\"Stato del grafo e delle associazioni caricato.\")\n",
    "\n",
    "# Classe TextToGraph\n",
    "class TextToGraph:\n",
    "    def __init__(self):\n",
    "        self.graph_model = ThreeDimensionalGraphModel()\n",
    "        self.node_dict = {}\n",
    "        self.reverse_node_dict = {}\n",
    "        self.concept_dict = {}\n",
    "        self.reverse_concept_dict = {}\n",
    "        self.text = \"\"\n",
    "\n",
    "    def process_text(self, text, nlp):\n",
    "        self.text = text\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sents:\n",
    "            subject, obj = None, None\n",
    "            relation = 'default'\n",
    "            for token in sent:\n",
    "                if not token.is_stop and not token.is_punct:\n",
    "                    if \"subj\" in token.dep_:\n",
    "                        subject = token.lemma_.lower()\n",
    "                    elif \"obj\" in token.dep_:\n",
    "                        obj = token.lemma_.lower()\n",
    "                    elif token.pos_ == 'VERB':\n",
    "                        relation = token.lemma_.lower()\n",
    "            if subject and obj:\n",
    "                subj = self._get_node(subject)\n",
    "                obj = self._get_node(obj)\n",
    "                probability = self._calculate_probability(subject, obj)\n",
    "                self.graph_model.add_connection(subj, obj, weight=1, probability=probability, relation_type=relation)\n",
    "\n",
    "    def _get_node(self, name):\n",
    "        if name not in self.node_dict:\n",
    "            new_index = len(self.node_dict)\n",
    "            self.node_dict[name] = new_index\n",
    "            self.reverse_node_dict[new_index] = name\n",
    "        return name\n",
    "\n",
    "    def _calculate_probability(self, subject, obj):\n",
    "        if fasttext_model:\n",
    "            similarity = calculate_similarity(subject, obj, fasttext_model)\n",
    "            probability = (similarity + 1) / 2\n",
    "            return probability\n",
    "        else:\n",
    "            return 0.5\n",
    "\n",
    "    def extract_concepts_clustering(self, num_concepts=10):\n",
    "        node_embeddings = []\n",
    "        node_names = []\n",
    "\n",
    "        for node in self.node_dict:\n",
    "            try:\n",
    "                embedding_vector = fasttext_model.get_word_vector(node)\n",
    "            except KeyError:\n",
    "                embedding_vector = np.random.randn(300)  # Supponendo dimensione 300\n",
    "            node_embeddings.append(embedding_vector)\n",
    "            node_names.append(node)\n",
    "\n",
    "        node_embeddings = np.array(node_embeddings)\n",
    "        clustering_model = KMeans(n_clusters=num_concepts, random_state=42)\n",
    "        labels = clustering_model.fit_predict(node_embeddings)\n",
    "        centroids = clustering_model.cluster_centers_\n",
    "\n",
    "        for concept_label in range(num_concepts):\n",
    "            cluster_indices = np.where(labels == concept_label)[0]\n",
    "            if len(cluster_indices) == 0:\n",
    "                continue\n",
    "            cluster_embeddings = node_embeddings[cluster_indices]\n",
    "            distances = np.linalg.norm(cluster_embeddings - centroids[concept_label], axis=1)\n",
    "            representative_idx = cluster_indices[np.argmin(distances)]\n",
    "            representative_name = node_names[representative_idx]\n",
    "\n",
    "            if representative_name not in self.concept_dict:\n",
    "                new_concept_idx = len(self.concept_dict)\n",
    "                self.concept_dict[representative_name] = new_concept_idx\n",
    "                self.reverse_concept_dict[new_concept_idx] = representative_name\n",
    "            else:\n",
    "                new_concept_idx = self.concept_dict[representative_name]\n",
    "\n",
    "            for idx in cluster_indices:\n",
    "                node = node_names[idx]\n",
    "                self.graph_model.add_concept_association(new_concept_idx, node, strength=1.0)\n",
    "\n",
    "    def save_state(self, filename):\n",
    "        with open(filename + '_node_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(self.node_dict, f)\n",
    "        with open(filename + '_reverse_node_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(self.reverse_node_dict, f)\n",
    "        with open(filename + '_concept_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(self.concept_dict, f)\n",
    "        with open(filename + '_reverse_concept_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(self.reverse_concept_dict, f)\n",
    "        self.graph_model.save_state(filename)\n",
    "\n",
    "    def load_state(self, filename):\n",
    "        with open(filename + '_node_dict.pkl', 'rb') as f:\n",
    "            self.node_dict = pickle.load(f)\n",
    "        with open(filename + '_reverse_node_dict.pkl', 'rb') as f:\n",
    "            self.reverse_node_dict = pickle.load(f)\n",
    "        with open(filename + '_concept_dict.pkl', 'rb') as f:\n",
    "            self.concept_dict = pickle.load(f)\n",
    "        with open(filename + '_reverse_concept_dict.pkl', 'rb') as f:\n",
    "            self.reverse_concept_dict = pickle.load(f)\n",
    "        self.graph_model.load_state(filename)\n",
    "\n",
    "    def print_nodes_and_connections(self):\n",
    "        \"\"\"\n",
    "        Stampa i nodi e le loro connessioni con peso, probabilità e tipo di relazione.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Nodi e Connessioni ---\")\n",
    "        G = self.graph_model.G\n",
    "        if G is not None and G.number_of_edges() > 0:\n",
    "            for edge in G.edges(data=True):\n",
    "                source, target, data = edge\n",
    "                weight = data.get('weight', 1)\n",
    "                probability = data.get('probability', 1.0)\n",
    "                relation_types = data.get('relation_types', {'default'})\n",
    "                print(f\"Connessione da '{source}' a '{target}' con peso {weight}, probabilità {probability:.2f}, relazione: {relation_types}\")\n",
    "        else:\n",
    "            print(\"Nessuna connessione trovata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella creiamo una classe per visulizzare il grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ildbj5D5sZqb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def visualize_graph_3d(graph_model):\n",
    "    \"\"\"\n",
    "    Visualizza il grafo in 3D utilizzando Plotly.\n",
    "    \"\"\"\n",
    "    # Calcolo del layout 3D\n",
    "    pos = nx.spring_layout(graph_model.G, dim=3, seed=42)\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_z = []\n",
    "\n",
    "    # Aggiunge le coordinate degli archi\n",
    "    for edge in graph_model.G.edges():\n",
    "        x0, y0, z0 = pos[edge[0]]\n",
    "        x1, y1, z1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_z.extend([z0, z1, None])\n",
    "\n",
    "    # Traccia degli archi\n",
    "    edge_trace = go.Scatter3d(\n",
    "        x=edge_x, y=edge_y, z=edge_z,\n",
    "        line=dict(width=1, color='blue'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_z = []\n",
    "    node_text = []\n",
    "\n",
    "    # Aggiunge le coordinate dei nodi\n",
    "    for node in graph_model.G.nodes():\n",
    "        x, y, z = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_z.append(z)\n",
    "        node_text.append(node)  # Nome del nodo\n",
    "\n",
    "    # Traccia dei nodi\n",
    "    node_trace = go.Scatter3d(\n",
    "        x=node_x, y=node_y, z=node_z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='red',\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=node_text,\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "\n",
    "    # Configura la visualizzazione\n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title='Grafo di Conoscenza 3D',\n",
    "                        showlegend=False,\n",
    "                        scene=dict(\n",
    "                            xaxis=dict(showbackground=False),\n",
    "                            yaxis=dict(showbackground=False),\n",
    "                            zaxis=dict(showbackground=False)\n",
    "                        ),\n",
    "                        margin=dict(l=0, r=0, b=0, t=40)\n",
    "                    ))\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa cella serve per eseguire dei debug e per salvare o caricare il grafo in un formato pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 1417,
     "status": "error",
     "timestamp": 1732093339130,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "zsMtu-7X5gWN",
    "outputId": "7636cad5-c1f8-40a7-e90f-5b563062ebc9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "# Carica il grafo salvato\n",
    "with open(\"modello_salvato_G.pkl\", \"rb\") as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "# Stampa informazioni sul grafo\n",
    "print(\"Informazioni sul Grafo:\")\n",
    "\n",
    "# Visualizza i nodi e gli archi\n",
    "print(\"\\nNodi nel grafo:\")\n",
    "print(graph.nodes(data=True))\n",
    "\n",
    "print(\"\\nArchi nel grafo:\")\n",
    "print(graph.edges(data=True))\n",
    "\n",
    "# Carica le associazioni concetto-nodo\n",
    "with open(\"modello_salvato_C.pkl\", \"rb\") as f:\n",
    "    concept_associations = pickle.load(f)\n",
    "\n",
    "# Stampa le associazioni\n",
    "print(\"\\nAssociazioni Concetto-Nodo:\")\n",
    "for concept, nodes in concept_associations.items():\n",
    "    print(f\"Concetto '{concept}':\")\n",
    "    for node, strength in nodes.items():\n",
    "        print(f\"  Nodo: {node}, Forza: {strength}\")\n",
    "\n",
    "# Carica il dizionario dei nodi\n",
    "with open(\"modello_salvato_node_dict.pkl\", \"rb\") as f:\n",
    "    node_dict = pickle.load(f)\n",
    "\n",
    "# Carica il dizionario inverso dei nodi\n",
    "with open(\"modello_salvato_reverse_node_dict.pkl\", \"rb\") as f:\n",
    "    reverse_node_dict = pickle.load(f)\n",
    "\n",
    "# Stampa i dizionari\n",
    "print(\"\\nDizionario dei Nodi:\")\n",
    "print(node_dict)\n",
    "\n",
    "print(\"\\nDizionario Inverso dei Nodi:\")\n",
    "print(reverse_node_dict)\n",
    "\n",
    "# Carica il dizionario dei concetti\n",
    "with open(\"modello_salvato_concept_dict.pkl\", \"rb\") as f:\n",
    "    concept_dict = pickle.load(f)\n",
    "\n",
    "# Carica il dizionario inverso dei concetti\n",
    "with open(\"modello_salvato_reverse_concept_dict.pkl\", \"rb\") as f:\n",
    "    reverse_concept_dict = pickle.load(f)\n",
    "\n",
    "# Stampa i dizionari\n",
    "print(\"\\nDizionario dei Concetti:\")\n",
    "print(concept_dict)\n",
    "\n",
    "print(\"\\nDizionario Inverso dei Concetti:\")\n",
    "print(reverse_concept_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'ultima cella definiamo la main function e istanziamo gli oggetti per testare il tutto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1732044405745,
     "user": {
      "displayName": "luca persichini",
      "userId": "15811526394363203850"
     },
     "user_tz": -60
    },
    "id": "HQHOFo1b430m",
    "outputId": "2c303462-b28d-4ef7-972c-9b06f85a96ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stato del grafo e delle associazioni caricato.\n",
      "Stato precedente caricato.\n",
      "\n",
      "Processo del testo...\n",
      "\n",
      "--- Nodi e Connessioni ---\n",
      "\n",
      "--- Nodi e Connessioni ---\n",
      "Connessione da 'osservazione' a 'inizio' con peso 2, probabilità 0.68, relazione: {'segnare'}\n",
      "Connessione da 'processo' a 'equilibrio' con peso 2, probabilità 0.64, relazione: {'sostenere'}\n",
      "Connessione da 'alan' a 'pensiero' con peso 2, probabilità 0.52, relazione: {'simulare'}\n",
      "Connessione da 'algoritmi' a 'quantità' con peso 2, probabilità 0.58, relazione: {'analizzare'}\n",
      "Connessione da 'cambio' a 'innalzamento' con peso 2, probabilità 0.71, relazione: {'causare'}\n",
      "Connessione da 'accordo' a 'aumento' con peso 2, probabilità 0.63, relazione: {'limitare'}\n",
      "Connessione da 'friedrich' a 'conseguenza' con peso 2, probabilità 0.56, relazione: {'esplorare'}\n",
      "Connessione da 'mutazione' a 'comprensione' con peso 2, probabilità 0.66, relazione: {'identificare'}\n",
      "Connessione da 'crispr-cas9' a 'genoma' con peso 2, probabilità 0.62, relazione: {'modificare'}\n",
      "Connessione da 'scoperta' a 'finestra' con peso 2, probabilità 0.58, relazione: {'aprire'}\n",
      "Connessione da 'onda' a 'informazione' con peso 2, probabilità 0.66, relazione: {'trasportare'}\n",
      "Connessione da 'civiltà' a 'scrittura' con peso 2, probabilità 0.66, relazione: {'permettere'}\n",
      "Connessione da 'egizi' a 'oggetto' con peso 2, probabilità 0.55, relazione: {'utilizzare'}\n",
      "Connessione da 'formica' a 'feromone' con peso 2, probabilità 0.63, relazione: {'orientare si'}\n",
      "Connessione da 'intelligenza' a 'modello' con peso 2, probabilità 0.58, relazione: {'rappresentare'}\n",
      "Connessione da 'dante' a 'viaggio' con peso 2, probabilità 0.56, relazione: {'descrire'}\n",
      "Stato del grafo e delle associazioni salvati.\n",
      "\n",
      "Stato aggiornato salvato correttamente.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Nome base per i file di salvataggio\n",
    "    save_filename = 'modello_salvato'\n",
    "\n",
    "    # Testo complesso di esempio\n",
    "    text = \"\"\"\n",
    "Nel XVII secolo, Galileo Galilei introdusse il metodo scientifico, rivoluzionando la comprensione dell'universo e affrontando l'opposizione della Chiesa cattolica.\n",
    "Le sue osservazioni delle fasi di Venere e delle lune di Giove supportarono il modello eliocentrico di Copernico, segnando l'inizio della scienza moderna.\n",
    "\n",
    "La fotosintesi, un processo scoperto da Jan Ingenhousz nel XVIII secolo, converte l'energia solare in glucosio, con l'ossigeno come sottoprodotto.\n",
    "Questo processo è essenziale per mantenere l'equilibrio dei gas atmosferici e sostenere la vita sulla Terra.\n",
    "\n",
    "Nel XX secolo, Alan Turing sviluppò i concetti fondamentali dell'intelligenza artificiale, introducendo l'idea di una macchina capace di simulare il pensiero umano.\n",
    "Oggi, gli algoritmi di machine learning vengono utilizzati per analizzare grandi quantità di dati, con applicazioni nella medicina, nella finanza e nella robotica.\n",
    "\n",
    "Il cambio climatico, intensificato dall'aumento delle emissioni di CO2, sta causando l'innalzamento del livello del mare, scioglimento dei ghiacciai e eventi meteorologici estremi.\n",
    "L'accordo di Parigi del 2015 ha cercato di unire le nazioni per limitare l'aumento della temperatura globale a 1.5°C rispetto ai livelli preindustriali.\n",
    "\n",
    "Filosoficamente, Immanuel Kant sosteneva che il tempo e lo spazio fossero forme a priori della conoscenza, mentre Friedrich Nietzsche dichiarava la \"morte di Dio\", esplorando le conseguenze morali e culturali di un mondo senza valori assoluti.\n",
    "\n",
    "In biologia molecolare, la scoperta della doppia elica del DNA da parte di Watson e Crick ha fornito una comprensione della genetica, mentre le mutazioni geniche sono state identificate come la base dell'evoluzione e di molte malattie.\n",
    "La CRISPR-Cas9, una tecnica innovativa di editing genetico, permette oggi di modificare il genoma con una precisione senza precedenti.\n",
    "\n",
    "In astrofisica, la scoperta delle onde gravitazionali da parte del team di LIGO nel 2015 ha confermato un'altra previsione della teoria della relatività generale di Einstein, aprendo nuove finestre sull'universo.\n",
    "Queste onde, causate dalla fusione di buchi neri o stelle di neutroni, trasportano informazioni sulla struttura dello spazio-tempo.\n",
    "\n",
    "La civiltà mesopotamica, sviluppatasi tra i fiumi Tigri ed Eufrate, introdusse la scrittura cuneiforme, che permise la registrazione di leggi, transazioni commerciali e opere letterarie come l'Epopea di Gilgamesh.\n",
    "Nel frattempo, gli Egizi costruirono le piramidi, utilizzando avanzate tecniche di ingegneria ancora oggetto di studio.\n",
    "\n",
    "Un robot può oggi esplorare Marte, analizzare campioni di suolo e comunicare dati scientifici alla Terra, mentre una formica utilizza feromoni per orientarsi nel suo ambiente.\n",
    "L'intelligenza collettiva di un alveare rappresenta un modello biologico per la progettazione di algoritmi distribuiti.\n",
    "\n",
    "In letteratura, William Shakespeare esplorò la complessità dell'animo umano in opere come \"Amleto\" e \"Macbeth\", mentre Dante Alighieri, con la \"Divina Commedia\", descrisse un viaggio allegorico attraverso Inferno, Purgatorio e Paradiso.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Inizializzazione del modello TextToGraph\n",
    "    text_to_graph = TextToGraph()\n",
    "\n",
    "    # Carica lo stato precedente, se esiste\n",
    "    if os.path.exists(save_filename + '_G.pkl'):\n",
    "        text_to_graph.load_state(save_filename)\n",
    "        print(\"Stato precedente caricato.\")\n",
    "    else:\n",
    "        print(\"Nessun stato precedente trovato. Creazione di un nuovo modello.\")\n",
    "\n",
    "    # Processa il testo e aggiorna il grafo\n",
    "    print(\"\\nProcesso del testo...\")\n",
    "    text_to_graph.process_text(text, spacy_model)\n",
    "\n",
    "    # Stampa nodi e connessioni\n",
    "    print(\"\\n--- Nodi e Connessioni ---\")\n",
    "    text_to_graph.print_nodes_and_connections()\n",
    "\n",
    "    # Salva lo stato aggiornato\n",
    "    text_to_graph.save_state(save_filename)\n",
    "    print(\"\\nStato aggiornato salvato correttamente.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si vede dall'output vengono correttamente create all'interno del grafo le  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0t86KcyoL0enSeki+mp+2",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
